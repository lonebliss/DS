{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"18_YwOCbe7p969GUY2BmoI-CDiNBUM78p","authorship_tag":"ABX9TyNmGeUVKz36FMPr+0qy6/mL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jZubb2he5Y7N","executionInfo":{"status":"ok","timestamp":1733170180617,"user_tz":-330,"elapsed":813,"user":{"displayName":"Shiv Patel","userId":"11525742660927518818"}},"outputId":"47f7c846-558a-498a-f691-3de99f17a674"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input Data Values\n","                       Country ISO-2-CODE ISO-3-Code  ISO-M49\n","0                  Afghanistan         AF        AFG        4\n","1                Aland Islands         AX        ALA      248\n","2                      Albania         AL        ALB        8\n","3                      Algeria         DZ        DZA       12\n","4               American Samoa         AS        ASM       16\n","..                         ...        ...        ...      ...\n","242  Wallis and Futuna Islands         WF        WLF      876\n","243             Western Sahara         EH        ESH      732\n","244                      Yemen         YE        YEM      887\n","245                     Zambia         ZM        ZMB      894\n","246                   Zimbabwe         ZW        ZWE      716\n","\n","[247 rows x 4 columns]\n","Process Data Values\n","                             CountryName\n","CountryNumber                           \n","716                             Zimbabwe\n","894                               Zambia\n","887                                Yemen\n","732                       Western Sahara\n","876            Wallis and Futuna Islands\n","...                                  ...\n","16                        American Samoa\n","12                               Algeria\n","8                                Albania\n","248                        Aland Islands\n","4                            Afghanistan\n","\n","[247 rows x 1 columns]\n","CSV to Horus done\n"]}],"source":["#P1\n","import pandas as pd\n","sInputFileName='/content/drive/MyDrive/Colab Notebooks/DS-DATA/country_code.csv'\n","InputData=pd.read_csv(sInputFileName,encoding=\"iso-8859-1\")\n","print('Input Data Values')\n","print(InputData)\n","ProcessData = InputData\n","ProcessData.drop('ISO-2-CODE', axis=1,inplace=True)\n","ProcessData.drop('ISO-3-Code', axis=1,inplace=True)\n","ProcessData.rename(columns={'Country': 'CountryName'}, inplace=True)\n","ProcessData.rename(columns={'ISO-M49': 'CountryNumber'}, inplace=True)\n","ProcessData.set_index('CountryNumber', inplace=True)\n","ProcessData.sort_values('CountryName', axis=0, ascending = False, inplace=True)\n","print('Process Data Values')\n","print(ProcessData)\n","OutputData = ProcessData\n","sOutputFileName='/content/country_code_processed.csv'\n","OutputData.to_csv(sOutputFileName, index=False)\n","print('CSV to Horus done')\n"]},{"cell_type":"code","source":["import pytesseract\n","from PIL import Image\n","# Load the image\n","img = Image.open('/content/download1.png')\n","# Use pytesseract to do OCR on the image\n","text = pytesseract.image_to_string(img)\n","print(\"Extracted text:\", text)"],"metadata":{"id":"v-kZjJZV5ank"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import numpy as np\n","# Load the image\n","img = Image.open('/content/11.JPG')\n","# Convert image to RGB\n","img = img.convert('RGB')\n","# Convert to numpy array\n","data = np.array(img)\n","# Reshape the array and get unique colors\n","reshaped_data = data.reshape(-1, 3)\n","unique_colors = np.unique(reshaped_data, axis=0)\n","print(f\"Number of unique colors: {len(unique_colors)}\")\n","print(f\"Unique colors: {unique_colors}\")"],"metadata":{"id":"EO7qQuqTA5M_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from moviepy.editor import VideoFileClip\n","# Load video file\n","video = VideoFileClip('/content/Data Science In 5 Minutes _ Data Science For Beginners _\n","What Is Data Science_ _ Simplilearn.mp4')\n","# Get duration in seconds\n","duration = video.duration\n","# Convert to hours\n","duration_seconds = duration / 3600\n","print(f\"Video duration in seconds: {duration_seconds}\")"],"metadata":{"id":"b82pbDKRBE_3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","import cv2\n","sInputFileName='/content/Data Science In 5 Minutes _ Data Science For Beginners _ What\n","Is Data Science_ _ Simplilearn.mp4'\n","sDataBaseDir='/content/'\n","print('Converting Movie to Frames')\n","vidcap = cv2.VideoCapture(sInputFileName)\n","success,image = vidcap.read()\n","\"\"\"# Converting Movie to Frames\"\"\"\n","count = 0\n","while success:\n"," success,image = vidcap.read()\n"," if not success: # Check if a frame was successfully read\n"," break # Exit the loop if no more frames\n"," sFrame=sDataBaseDir + str('/-' + str(format(count, '04d'))+ '.jpg')\n"," print('Extracted: ', sFrame)\n"," cv2.imwrite(sFrame, image)\n"," if os.path.getsize(sFrame) == 0:\n"," count += -1\n"," os.remove(sFrame)\n"," print('Removed: ', sFrame)\n"," if cv2.waitKey(10) == 27: # exit if Escape is hit\n"," break\n"," count += 1"],"metadata":{"id":"1q500nxwBIhH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#P2\n","import pandas as pd\n","sFileName='/content/IP_DATA_ALL.csv'\n","print('Loading :',sFileName)\n","IP_DATA_ALL=pd.read_csv(sFileName,header=0,low_memory=False,usecols=['Country','P\n","lace.Name','Latitude','Longitude'], encoding=\"latin-1\")\n","IP_DATA_ALL.rename(columns={'Place.Name': 'Place_Name'}, inplace=True)\n","LondonData=IP_DATA_ALL.loc[IP_DATA_ALL['Place_Name']=='London']\n","AllData=LondonData[['Country', 'Place_Name','Latitude']]\n","print('All Data')\n","print(AllData)\n","MeanData=AllData.groupby(['Country', 'Place_Name'])['Latitude'].mean()\n","StdData=AllData.groupby(['Country', 'Place_Name'])['Latitude'].std()\n","print('Outliers')\n","UpperBound= MeanData + StdData\n","UpperBound= UpperBound.astype(float)\n","print('Higher than ', UpperBound)"],"metadata":{"id":"ucGw8NyPBUD7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","sfileName='/content/IP_DATA_ALL.csv'\n","print('Loading :',sfileName)\n","IP_DATA_ALL=pd.read_csv(sfileName,header=0,low_memory=False,usecols=['Country','P\n","lace.Name','Latitude','Longitude'], encoding=\"latin-1\")\n","IP_DATA_ALL.rename(columns={'Place.Name': 'Place_Name'}, inplace=True)\n","AllData=IP_DATA_ALL[['Country', 'Place_Name','Latitude']]\n","print(AllData)\n","MeanData=AllData.groupby(['Country', 'Place_Name'])['Latitude'].mean()\n","print(MeanData)"],"metadata":{"id":"IKJT66rmBeDF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.mlab as mlab\n","import matplotlib.pyplot as plt\n","from scipy.stats import norm\n","np.random.seed(0)\n","# example data\n","mu = 90 # mean of distribution\n","sigma = 25 # standard deviation of distribution\n","x = mu + sigma * np.random.randn(5000)\n","num_bins = 25\n","fig, ax = plt.subplots()\n","# the histogram of the data\n","n, bins, patches = ax.hist(x, num_bins, density=1)\n","# add a 'best fit' line\n","y = norm.pdf(bins, mu, sigma)\n","ax.plot(bins, y, '--')\n","ax.set_xlabel('Example Data')\n","ax.set_ylabel('Probability density')\n","sTitle=r'Histogram ' + str(len(x)) + ' entries into ' + str(num_bins) + 'Bins: $\\mu=' + str(mu) +\n","'$, $\\sigma=' + str(sigma) + '$'\n","ax.set_title(sTitle)\n","fig.tight_layout()\n","plt.show()"],"metadata":{"id":"huFIJM_yBmeH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Removing leading or lagging spaces from a data entry\n","baddata = \" Data Science with too many spaces is bad!!! \" # This line was indented\n","unnecessarily\n","print('>',baddata,'<')\n","cleandata=baddata.strip()\n","print('>',cleandata,'<')\n","#Removing nonprintable characters from a data entry\n","import string\n","printable = set(string.printable)\n","baddata = \"Data\\x00Science with\\x02 funny characters is \\x10bad!!!\"\n","cleandata=''.join(filter(lambda x: x in string.printable,baddata))\n","print(cleandata)\n","#Reformatting data entry to match specific formatting criteria. Convert 2017/01/31 to 31\n","January 2017\n","import datetime as dt\n","baddate = dt.date(2017, 1, 31)\n","baddata=format(baddate,'%Y-%m-%d')\n","print(baddata)\n","gooddate = dt.datetime.strptime(baddata,'%Y-%m-%d')\n","gooddata=format(gooddate,'%d %B %Y')\n","print(gooddata)\n"],"metadata":{"id":"EfcufLF3BoMM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#P3\n","import os\n","import pandas as pd\n","InputFileName='/content/IP_DATA_ALL.csv'\n","OutputFileName=\"Retrive_Router_Location.csv\"\n","sFileName=\"/content/IP_DATA_ALL.csv\"\n","print('Loading :',sFileName)\n","IP_DATA_ALL=pd.read_csv(sFileName,header=0,low_memory=False,\n"," usecols=['Country','Place.Name','Latitude','Longitude'])\n","IP_DATA_ALL.rename(columns={'Place.Name': 'Place_name'}, inplace=True)\n","sFileDir='/content/'\n","ROUTERLOC = IP_DATA_ALL.drop_duplicates(subset=None, keep='first',\n"," inplace=False)\n","print('Rows :' ,ROUTERLOC.shape[0])\n","print('Columns:' ,ROUTERLOC.shape[1])\n","sFileName2=sFileDir + '/' + OutputFileName\n","ROUTERLOC.to_csv(sFileName2, index = False)\n","print('Done!!')"],"metadata":{"id":"4DfsoRClB48i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#P4\n","import pandas as pd\n","import numpy as np\n","df = pd.DataFrame([[10, np.nan, 30,40],[7,14,21,28],[55,np.nan,8,12],\n"," [15,14,np.nan,8],[7,1,1,np.nan],[np.nan, 4,9,2]],\n"," columns=['Apple','Orange','Banana','Pear'],\n"," index=['Basket1','Basket2','Basket3','Basket4',\n"," 'Basket5','Basket6'])\n","print(\"#########################\")\n","print(\"THE ORIGINAL VALUES\")\n","print(df)\n","print(\"REPLACING THE VALUES WITH MEAN\")\n","df.fillna(df.mean(),inplace=True)\n","df"],"metadata":{"id":"lMJd8jukCAcI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","df = pd.DataFrame([[10, np.nan, 30,40],[7,14,21,28],[55,np.nan,8,12],\n"," [15,14,np.nan,8],[7,1,1,np.nan],[np.nan, 4,9,2]],\n"," columns=['Apple','Orange','Banana','Pear'],\n"," index=['Basket1','Basket2','Basket3','Basket4',\n"," 'Basket5','Basket6'])\n","print(\"#########################\")\n","print(\"THE ORIGINAL VALUES\")\n","print(df)\n","print(\"REPLACING THE VALUES WITH MEAN\")\n","df.fillna(df.median(),inplace=True)\n","df"],"metadata":{"id":"KyPEZB_OCD7U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","df = pd.DataFrame([[10, np.nan, 30,40],[7,14,21,28],[55,np.nan,8,12],\n"," [15,14,np.nan,8],[7,1,1,np.nan],[np.nan, 4,9,2]],\n"," columns=['Apple','Orange','Banana','Pear'],\n"," index=['Basket1','Basket2','Basket3','Basket4',\n"," 'Basket5','Basket6'])\n","print(\"#########################\")\n","print(\"THE ORIGINAL VALUES\")\n","print(df)\n","print(\"REPLACING THE VALUES WITH MEAN\")\n","for column in df.columns :\n","df[column].fillna(df[column].mode(), inplace=True)\n","df\n"],"metadata":{"id":"OdBqyP7UCJPm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","df = pd.DataFrame([[10, np.nan, 30,40],[7,14,21,28],[55,np.nan,8,12],\n"," [15,14,np.nan,8],[7,1,1,np.nan],[np.nan, 4,9,2]],\n"," columns=['Apple','Orange','Banana','Pear'],\n"," index=['Basket1','Basket2','Basket3','Basket4',\n"," 'Basket5','Basket6'])\n","print(\"#########################\")\n","print(\"THE ORIGINAL VALUES\")\n","print(df)\n","print(\"REPLACING THE VALUES WITH MEAN\")\n","df.fillna(df.min(),inplace=True)\n","df"],"metadata":{"id":"hhCwL6YECLgo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#P5\n","#Important module and library to run the program\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.linear_model import LinearRegression\n","df = pd.read_csv(\"/content/Potato_Price.csv\")\n","#df for dataframe, read the data from the csv data file\n","df\n","# For the data visualization\n","%matplotlib inline\n","plt.xlabel('Potato in kilogram(kg)')\n","plt.ylabel('price in Taka')\n","plt.scatter(df.potato_kg, df.price)\n","X = df[['potato_kg']] #since x have to be two dimentional or 2D array. So [[]]\n","y=df['price']\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n","X_train\n","X_test\n","y_train\n","reg=LinearRegression()\n","reg.fit(X_train, y_train)\n","y_test\n","reg.predict(X_test)\n","y_test\n","reg.score(X_test, y_test)\n","# Give any unknown potato kilogram value, to know the price\n","#(N.B: the potato kilogram value have to be any value upto 1, for the decent prediction. Since\n","our fitted data potato_kg range is 1 to 7)\n","reg.predict([[1.1505659]])\n","#Simple user interface to run our model the model\n","x=input('To know the potato price, Enter the potato killogram upto 1:')\n","array = np.array(x) #input converted into 1 dimentional array\n","fvalu=array.astype(float) # 1 dimentional array into 1 dimentional float array\n","fvalu_2D=([[fvalu]]) # 1 dimentional array to 2 dimentional array\n","#print (fvalu_2D)\n","my_prediction=reg.predict(fvalu_2D)\n","#print(my_prediction)\n","#price=np.asscalar (np.array(my_prediction))\n","#convert vector into scalar using this one line only\n","#convert vector into scalar using below two lines\n","price=np.array(my_prediction)\n","price-price.item()\n","print('So',x,' killogram potato price is ', price, 'Dollars')\n"],"metadata":{"id":"kwB9cHq3CgDp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#P6\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.datasets import make_blobs\n","import matplotlib.pyplot as plt\n","# Sample data\n","X, _ = make_blobs(n_samples=300, centers=4, random_state=42)\n","# Preprocess the data\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","# Apply K-Means\n","kmeans = KMeans(n_clusters=4, random_state=42)\n","kmeans.fit(X_scaled)\n","labels = kmeans.labels_\n","# Visualize the clusters\n","plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels, cmap='viridis')\n","plt.show()\n"],"metadata":{"id":"p_nKnUgUCuT2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#P7\n","import nltk\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","Txt = \"Good Day Mr. Vermeulen, \\\n","how are you doing today? \\\n","The weather is great, and Data Science is awesome. \\\n","You are doing well!\"\n","print (Txt, '\\n')\n","print ('Identify sentences')\n","print (sent_tokenize (Txt), '\\n')\n","print('Identify Word')\n","print (word_tokenize (Txt))"],"metadata":{"id":"ANvNlYojC0Pc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#P8\n","import sys\n","import os\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","sPicName='/content/download.jpeg'\n","nSize=4\n","img = Image.open(sPicName)\n","plt.figure(figsize=(nSize, nSize))\n","sTitle='Unchanges'\n","plt.title(sTitle)\n","imgplot = plt.imshow(img)"],"metadata":{"id":"qLv51waGC6A-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img. thumbnail ((64, 64), Image. ANTIALIAS)\n","# resizes image in-place\n","plt. figure(figsize=(nSize, nSize))\n","sTitle= 'Resized'\n","plt.title(sTitle)\n","imgplot = plt. imshow(img)\n","plt. figure(figsize=(nSize, nSize))\n","sTitle='Resized with Bi-Cubic'\n","plt.title(sTitle)\n","imgplot = plt.imshow(img, interpolation=\"bicubic\")\n","print('### Done!! ##')"],"metadata":{"id":"4E-GHp4GDAyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#P9\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import datasets\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix\n","# Load the Iris dataset\n","iris = datasets.load_iris()\n","X = iris.data[:, :2] # Use only the first two features for visualization\n","y = iris.target\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","# Create an SVM classifier\n","model = svm.SVC(kernel='linear', C=1.0)\n","# Train the model\n","model.fit(X_train, y_train)\n","# Make predictions\n","y_pred = model.predict(X_test)\n","# Evaluate the model\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test, y_pred))\n","# Visualize the decision boundary\n","def plot_decision_boundary(model, X, y):\n"," x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n"," y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n"," xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n"," np.arange(y_min, y_max, 0.01))\n"," Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n"," Z = Z.reshape(xx.shape)\n","  plt.contourf(xx, yy, Z, alpha=0.8)\n"," plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o')\n"," plt.title(\"SVM Decision Boundary\")\n"," plt.xlabel(iris.feature_names[0])\n"," plt.ylabel(iris.feature_names[1])\n"," plt.show()\n","# Call the plot function\n","plot_decision_boundary(model, X, y)\n"],"metadata":{"id":"QoCGBdzgDIT1"},"execution_count":null,"outputs":[]}]}